{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#######################################################################################\n",
                "# Author: Srijan Verma                                                              #\n",
                "# School of Pharmacy                                                                #\n",
                "# Sirimulla Research Group [http://www.sirimullaresearchgroup.com/]                 #\n",
                "# The University of Texas at El Paso, TX, USA                                       #\n",
                "# Last modified: 19/12/2019                                                         #\n",
                "# Copyright (c) 2019 Srijan Verma and Sirimulla Research Group, under MIT license   #\n",
                "#######################################################################################"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import model_selection\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.svm import SVC\n",
                "import sys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score, log_loss\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
                "from xgboost import XGBClassifier\n",
                "from pandas.plotting import scatter_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn import model_selection\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.dummy import DummyClassifier\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "import os\n",
                "from sklearn.metrics import cohen_kappa_score\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import roc_auc_score\n",
                "from sklearn.metrics import precision_recall_curve\n",
                "from sklearn.metrics import auc\n",
                "import time\n",
                "#Documentation of hypopt - https://www.pydoc.io/pypi/hypopt-1.0.3/autoapi/model_selection/index.html\n",
                "#Edited version -> added cohen score as metric!\n",
                "from hypopt import GridSearch\n",
                "from sklearn.ensemble import BaggingClassifier\n",
                "from sklearn.naive_bayes import BernoulliNB\n",
                "from sklearn.naive_bayes import ComplementNB\n",
                "from sklearn.ensemble import ExtraTreesClassifier #Compare with decision tree\n",
                "from sklearn.gaussian_process import GaussianProcessClassifier\n",
                "# explicitly require this experimental feature\n",
                "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
                "# now you can import normally from ensemble\n",
                "from sklearn.ensemble import HistGradientBoostingClassifier\n",
                "from sklearn.tree import ExtraTreeClassifier #Compare with decision tree\n",
                "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
                "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier, OutputCodeClassifier\n",
                "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.load('../dataset/whichp450/numpy_files/lecfp6_laval_hashap_rdkDes-2E1.npy')\n",
                "X = arr[:,0:(arr.shape[1]-1)]\n",
                "Y = arr[:,(arr.shape[1]-1)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.15, random_state=7, stratify=Y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.load('../dataset/whichp450/numpy_files/lecfp6-independent_test.npy')\n",
                "X_test = arr[:,0:(arr.shape[1]-1)]\n",
                "y_test = arr[:,(arr.shape[1]-1)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
                            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
                            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
                            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
                            "              nthread=None, objective='binary:logistic', random_state=0,\n",
                            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
                            "              silent=None, subsample=1, verbosity=1)"
                        ]
                    },
                    "execution_count": 107,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "opt = RandomForestClassifier(n_estimators=10,random_state=None)\n",
                "opt = XGBClassifier()\n",
                "opt.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "opt.para"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_predictions = opt.predict(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc = accuracy_score(y_test, test_predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8980891719745223"
                        ]
                    },
                    "execution_count": 110,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
                            "       0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
                            "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0.], dtype=float16)"
                        ]
                    },
                    "execution_count": 111,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
                            "       0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
                            "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
                            "       0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
                            "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
                            "       0., 0., 0., 0.], dtype=float16)"
                        ]
                    },
                    "execution_count": 112,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_rep = classification_report(y_test, test_predictions,output_dict=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'0.0': {'precision': 0.9084507042253521,\n",
                            "  'recall': 0.9772727272727273,\n",
                            "  'f1-score': 0.9416058394160584,\n",
                            "  'support': 132},\n",
                            " '1.0': {'precision': 0.8, 'recall': 0.48, 'f1-score': 0.6, 'support': 25},\n",
                            " 'accuracy': 0.8980891719745223,\n",
                            " 'macro avg': {'precision': 0.8542253521126761,\n",
                            "  'recall': 0.7286363636363636,\n",
                            "  'f1-score': 0.7708029197080292,\n",
                            "  'support': 157},\n",
                            " 'weighted avg': {'precision': 0.8911814838073026,\n",
                            "  'recall': 0.8980891719745223,\n",
                            "  'f1-score': 0.8872100051141383,\n",
                            "  'support': 157}}"
                        ]
                    },
                    "execution_count": 114,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "class_rep"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.545750452079566"
                        ]
                    },
                    "execution_count": 115,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cohen_kappa_score(y_test, test_predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "metadata": {},
            "outputs": [],
            "source": [
                "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
                "    \n",
                "    #creating a set of all the unique classes using the actual class list\n",
                "    unique_class = set(actual_class)\n",
                "    roc_auc_dict = {}\n",
                "    for per_class in unique_class:\n",
                "        #creating a list of all the classes except the current class\n",
                "        other_class = [x for x in unique_class if x != per_class]\n",
                "        \n",
                "        #marking the current class as 1 and all other classes as 0\n",
                "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
                "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
                "        \n",
                "        #using the sklearn metrics method to calculate the roc_auc_score\n",
                "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
                "        roc_auc_dict[per_class] = roc_auc\n",
                "    \n",
                "    return roc_auc_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "metadata": {},
            "outputs": [],
            "source": [
                "auc_outputs = roc_auc_score_multiclass(y_test, test_predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{0.0: 0.7286363636363636, 1.0: 0.7286363636363636}"
                        ]
                    },
                    "execution_count": 118,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "auc_outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../dataset/whichp450/train.csv',index_col=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_list=list(df['drug_type'].unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "270cb924a53c453598766b06722d2b2b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "from tqdm import tqdm_notebook\n",
                "# df = df_deduplicated\n",
                "for k in tqdm_notebook(target_list):\n",
                "    \n",
                "    if k == '-':\n",
                "        continue\n",
                "        \n",
                "    else:\n",
                "    \n",
                "        label = []\n",
                "\n",
                "        for i in (range(len(df))):\n",
                "\n",
                "            if df['drug_type'][i] == k:\n",
                "                label.append('positive')\n",
                "                continue\n",
                "\n",
                "            else:\n",
                "                label.append('negative')\n",
                "                continue\n",
                "\n",
                "        df['Label'] = label\n",
                "\n",
                "        df_all = df\n",
                "\n",
                "        df_all.reset_index(drop = True, inplace = True)\n",
                "\n",
                "        drop_index = []\n",
                "\n",
                "        for i in (range(len(df_all))):\n",
                "\n",
                "            if df_all['drug_type'][i] == k:\n",
                "                continue\n",
                "\n",
                "            else:\n",
                "                drop_index.append(i)\n",
                "                continue\n",
                "\n",
                "        df_p = df_all.drop(drop_index, axis = 0, inplace = False)\n",
                "        df_p.reset_index(drop = True, inplace = True)\n",
                "\n",
                "        df_pos = df_p.drop_duplicates(['Smiles'])\n",
                "\n",
                "        uni_pos_smiles = set(df_pos['Smiles'].tolist())\n",
                "\n",
                "        drop_index = []\n",
                "        for i in (range(len(df_all))):\n",
                "\n",
                "            if df_all['Smiles'][i] in uni_pos_smiles:\n",
                "                drop_index.append(i)\n",
                "                continue\n",
                "\n",
                "            else:\n",
                "                continue\n",
                "\n",
                "        df_neg = df_all.drop(drop_index, axis = 0, inplace = False)\n",
                "        df_neg.reset_index(drop = True, inplace = True)\n",
                "\n",
                "        df_neg = df_neg.drop_duplicates(['Smiles'])\n",
                "\n",
                "    #########################<GETTING FAM-SMILES-COUNT>####################################\n",
                "        df_neg.reset_index(drop = True, inplace = True)\n",
                "        df_pos.reset_index(drop = True, inplace = True)\n",
                "\n",
                "    #     df_neg_index = df_neg.set_index('Final_Family')\n",
                "    #     df_pos_index = df_pos.set_index('Final_Family')\n",
                "\n",
                "    #     for fam in tqdm_notebook(fin_fam):\n",
                "    #         get_fam_count(k, fam, df_neg_index, df_pos_index) \n",
                "    #######################################################################################\n",
                "\n",
                "        clean_data = pd.concat([df_neg, df_pos], ignore_index=True, sort =True)\n",
                "\n",
                "#         if k.split('-')[1] == 'Inhibitor':\n",
                "#             clean_data.to_csv('../dataset/two_paper_plus_transformer_combined/inhib_data/' + k.split('-')[0] + '_inh.csv')\n",
                "#             continue\n",
                "\n",
                "#         elif k.split('-')[1] == 'Substrate':\n",
                "#             clean_data.to_csv('../dataset/two_paper_plus_transformer_combined/sub_data/' + k.split('-')[0] + '_sub.csv')\n",
                "            \n",
                "#         else:\n",
                "        clean_data.to_csv('../dataset/whichp450/individual_csv_files/' + k+'.csv')\n",
                "            \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python [conda env:seqcomhol]",
            "language": "python",
            "name": "conda-env-seqcomhol-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}